import numpy as np
import tensorflow as tf
from sklearn import preprocessing

mod_types = ['a16QAM', 'a64QAM', 'b8PSK', 'bQPSK', 'cCPFSK', 'cGFSK', 'd4PAM', 'dBPSK']

# fit a label binarizer
mod_to_onehot = preprocessing.LabelBinarizer()
mod_to_onehot.fit(mod_types)

# transform the y values to one-hot encoding
# y_train = mod_to_onehot.transform(y_train)

# Normalisation is very important


def iq2ampphase(inphase, quad):
    amplitude = np.sqrt(np.square(inphase) + np.square(quad))
    amp_norm = np.linalg.norm(amplitude)  # L2 norm
    amplitude = amplitude/amp_norm  # normalise
    phase = np.arctan(np.divide(quad, inphase))
    phase = 2.*(phase - np.min(phase))/np.ptp(phase)-1  # rescale phase to range [-1, 1]
    return amplitude, phase

# convert array of multiple iq samples into array of multiple ampphase samples


def arr_iq2ap(X):
    X_ap = []
    I = X[0, :]
    Q = X[1, :]
    amp, phase = iq2ampphase(I, Q)
    ap = np.array([amp, phase])
    return ap


qpsk = arr_iq2ap(np.array([[-0.00106607, -0.00280934, -0.00424631, -0.00557008, -0.00719865,
                            -0.00773249, -0.00889617, -0.00915022, -0.0090135, -0.00849538,
                            -0.00779735, -0.00578458, -0.00408238, -0.00139934,  0.00121199,
                            0.00313161,  0.00453308,  0.00523574,  0.00672356,  0.00644043,
                            0.00559538,  0.00425896,  0.00218745,  0.00023023, -0.00190739,
                            -0.00406587, -0.00482816, -0.00668124, -0.00722559, -0.00728381,
                            -0.00741554, -0.00673547, -0.00615885, -0.0055549, -0.00518738,
                            -0.00505246, -0.00439203, -0.005599, -0.00570744, -0.00594712,
                            -0.00614697, -0.00603104, -0.00557464, -0.00484321, -0.00517393,
                            -0.00457077, -0.00465665, -0.00442965, -0.00477882, -0.00468472,
                            -0.0056068, -0.00515847, -0.0066133, -0.00655651, -0.00692869,
                            -0.00665583, -0.00633696, -0.00568572, -0.00534168, -0.00561901,
                            -0.00644571, -0.00541382, -0.00615138, -0.00671358, -0.00721089,
                            -0.00781817, -0.00685751, -0.00604621, -0.0046152, -0.00258294,
                            -0.00050582,  0.00209414,  0.00406802,  0.00600435,  0.00654875,
                            0.00682339,  0.00607739,  0.00467684,  0.00258504, -0.000199,
                            -0.00301816, -0.00502004, -0.00657726, -0.00652967, -0.00665993,
                            -0.00504255, -0.00310162, -0.0012966,  0.00091561,  0.00361252,
                            0.00512935,  0.00650325,  0.00745751,  0.00723207,  0.00742037,
                            0.0064343,  0.00614984,  0.00551349,  0.0050486,  0.0051364,
                            0.00455889,  0.00498115,  0.00624187,  0.00657173,  0.00678716,
                            0.00732651,  0.00754048,  0.00718545,  0.00518534,  0.00406997,
                            0.00162073, -0.00025082, -0.00293499, -0.00377619, -0.00534553,
                            -0.00600939, -0.00718097, -0.00708029, -0.00708235, -0.00640236,
                            -0.00582171, -0.00551756, -0.00493587, -0.00583968, -0.00588759,
                            -0.00729255, -0.0073363, -0.00810693],
                           [0.00468482,  0.00579211,  0.00643247,  0.00600916,  0.00570389,
                            0.00377407,  0.00315742,  0.0007924, -0.0018479, -0.00380623,
                            -0.00609072, -0.00768665, -0.00830979, -0.00913707, -0.00823536,
                            -0.00740426, -0.00682968, -0.00638224, -0.00615377, -0.00471077,
                            -0.00438953, -0.00393747, -0.00417181, -0.00433674, -0.00499594,
                            -0.00525372, -0.00545764, -0.0061621, -0.0059875, -0.00611027,
                            -0.00577645, -0.00563965, -0.00488411, -0.00518724, -0.00508803,
                            -0.00505576, -0.00623069, -0.00626124, -0.00686382, -0.00735709,
                            -0.00814936, -0.00777651, -0.00701466, -0.00644676, -0.00453045,
                            -0.00240682, -0.00043838,  0.00145809,  0.00330672,  0.00537946,
                            0.00633706,  0.00650613,  0.0056745,  0.00404582,  0.00258536,
                            0.00030592, -0.00194743, -0.00436415, -0.00582525, -0.00727339,
                            -0.00749297, -0.00784163, -0.00692389, -0.00629277, -0.00650966,
                            -0.00529701, -0.00527442, -0.00467228, -0.00597331, -0.00719882,
                            -0.0072292, -0.0077787, -0.00802021, -0.00828969, -0.00735036,
                            -0.0063884, -0.00401225, -0.0013978,  0.00128736,  0.00359192,
                            0.0052651,  0.00651864,  0.00718351,  0.00642077,  0.00572038,
                            0.00366427,  0.00177533, -0.00128429, -0.00308081, -0.00515864,
                            -0.00719729, -0.00759972, -0.00681062, -0.00735922, -0.0065721,
                            -0.00617174, -0.00532896, -0.00490188, -0.00407921, -0.0046711,
                            -0.00455828, -0.00550368, -0.00551922, -0.00689015, -0.00730317,
                            -0.00761632, -0.00644878, -0.00523394, -0.00397471, -0.00291976,
                            -0.00105397,  0.00157569,  0.00278913,  0.00421628,  0.00605849,
                            0.00666965,  0.007094,  0.00741811,  0.00783126,  0.00736777,
                            0.00678318,  0.00665134,  0.00655789,  0.00478476,  0.00437345,
                            0.00284984,  0.00161816, -0.00075401]]
                          ))

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="cldnn_ap_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
# print(input_details, '\n', output_details)

# Test the model on random input data.
input_shape = input_details[0]['shape']
# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
input_data = qpsk.reshape(input_shape).astype(np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.

output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
print(mod_to_onehot.inverse_transform(output_data))